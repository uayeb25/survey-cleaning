#   behavior of tests in other contexts."
# The eigenvalues of the U.Gamma matrix will be the coefficients in the
#   mixture of F's distribution (Skinner, Holt & Smith, pp. 86-87).
pval.pFsum <- function(lavaan.fit, survey.design, method = "saddlepoint") {
# Check that Satorra-Bentler or Satterthwaite adjustment is present
if(!lavInspect(lavaan.fit, "options")$test %in%
c("satorra.bentler", "mean.var.adjusted", "Satterthwaite")) {
stop("Please refit the model with Satorra-Bentler (MLM) or Satterthwaite (MLMVS) adjustment.")
}
UGamma <- lavTech(lavaan.fit, "ugamma")
real.eigen.values <- Re(eigen(lavTech(lavaan.fit, "ugamma"), only.values = TRUE)$values)
return(survey::pFsum(x=fitMeasures(lavaan.fit, "chisq"), df=rep(1, length(real.eigen.values)),
a=real.eigen.values, ddf=survey::degf(survey.design), lower.tail=FALSE,
method=method))
}
cleaning.db <- function(model_completo, var_lonely, dados) {
lista_variaveis <- catch.lista.variaveis(model_completo)
variaveis_do_modelo <- Reduce(intersect, list(lista_variaveis,colnames(dados)))
variaveis_do_modelo <- c(variaveis_do_modelo,var_lonely)
## transformar as vaiaveis usadas em numericas
indices_colunas <-  which(colnames(dados) %in% variaveis_do_modelo)
remove_vars <- NULL
for(i in 1:length(indices_colunas)){
j <- indices_colunas[i]
dados[,j] <-  as.numeric(as.character(dados[,j]))
summary <- summary(dados[,j])
if ((summary[7]/nrow(dados))>0.2) {
remove_vars <- cbind(remove_vars, colnames(dados)[j])
}
}
return(c(remove_vars))
}
catch.lista.variaveis <- function(model_completo) {
# agora vamos dividir entre constuctos e preditores
pegar1 <- unlist(strsplit(model_completo,
split=c("\n")))
pegar2 <- grep("=~", pegar1, value=T)
pegar3 <- list()
pegar4 <- c()
z <- 1
for(i in 1:length(pegar2)){
pegar3[i] <- strsplit(pegar2[i],
split=c("=~"))
pegar4[i] <- trimws(pegar2[[i]][1])
pegar4    <- trimws(pegar4)
}
# separar os preditores dentro de cada constructo
pegar5<-list()
for(i in 1:length(pegar3)){
## vamos dividir em cada elemento da parte dos preditores
pegar5[i] <- strsplit(pegar3[[i]][2],
split = c("\\+"))
}
# define a lista de variaveis do modelo, a partir dos constructos e das sozinhas
lista_variaveis     <- unlist(pegar5)
for (i in 1:length(lista_variaveis)) {
lista_variaveis[i] <- trimws(lista_variaveis[i])
}
return(lista_variaveis)
}
do.remove<- function(model_completo_aux, variaveis_removidas) {
## primeiro passo eh dividir os models latentes
model<-NULL
model<-unlist(strsplit(model_completo_aux,
split=c("\n")))
latent<-grep("=~", model, value=T)
reg<-grep("~", model, value = T)
reg<- reg[which(!reg %in%latent)]
# agora vamos dividir entre constuctos e 'preditores'
latentes<-list()
nome_constructo<-c()
for(i in 1:length(latent)){
latentes[i]<-strsplit(latent[i],
split=c("=~"))
nome_constructo[i]<-trimws(latentes[[i]][1])
nome_constructo<-trimws(nome_constructo)
}
# print("dividir entre constuctos e preditores:ok")
# separar os preditores dentro de cada constructo
pred<-list()
for(i in 1:length(latent)){
## vamos dividir em cada elemento da parte dos preditores
pred[i]<-strsplit(latentes[[i]][2],
split=c("\\+"))
}
varia<-(pred)
## colocar o nome do constructo em cada objeto
names(varia)<-trimws(nome_constructo)
### VAMOS TIRAR AQUELAS VARIAVEIS QUE FORAM RETIRADAS
### NA INSPECAO DE MISSINGS
k<-NULL
var_aux<-NULL
res<-NULL
aux<-NULL
for(i in 1:length(variaveis_removidas)){
variaveis_PROBLEMA_MATRIZ_aux<-variaveis_removidas[i]
res <- lapply(varia, function(ch) grep(variaveis_PROBLEMA_MATRIZ_aux, ch))
aux<-sapply(res, function(x) length(x) > 0)
if(sum(aux)>0){
var_aux<-names(which(aux==T))
k<-grep(variaveis_PROBLEMA_MATRIZ_aux, varia[[var_aux]])
varia[[var_aux]][k]<-NA
varia[[var_aux]]<-varia[[var_aux]][complete.cases(varia[[var_aux]])]
}
# variaveis_PROBLEMA_MATRIZ_aux<-NULL
k<-NULL
var_aux<-NULL
res<-NULL
aux<-NULL
}
HS.model<-NULL
for(i in 1:length(varia)){
va_lt<-NULL
va_lt[i]<-paste(names(varia)[i],"=~")
modelo<-NULL
var_lat<-(paste(unlist(varia[[i]]),"+"))
modelo<-paste(var_lat, collapse = " ")
modelo<-substr(modelo, 1, nchar(modelo)-2)
modelo<-paste(va_lt[i], modelo,"\n")
HS.model<-paste(HS.model, modelo)
}
va_lt<-NULL
constructos_excluidos <- NULL
## vamos tirar aquelas regressoes cujas variaveis independentes ficaram vazias
HS.model_aux <- NULL
HS.model_aux <-strsplit(HS.model,
split=c("\\n"))
for(i in 1:length(HS.model_aux[[1]])){
HS.model_aux2 <- NULL
HS.model_aux2<-strsplit(trimws(HS.model_aux[[1]][i]),
split=c("\\~"))
if(length(HS.model_aux2[[1]])<2){
HS.model_aux[[1]][i]<-NA
constructos_excluidos <- c(constructos_excluidos, sub(HS.model_aux2[[1]][1],pattern = "=",replacement = ""))
}
}
HS.model_aux <- HS.model_aux[[1]][complete.cases(HS.model_aux)]
for(i in 1:length(HS.model_aux)){
HS.model_aux3 <- NULL
HS.model_aux3<-strsplit(trimws(HS.model_aux[i]),
split=c("\\~"))
var_lat<-((strsplit(HS.model_aux3[[1]][2],split = c("\\+"))))
for (j in 1:length(var_lat[[1]])) {
var_lat[[1]][j]<-trimws(var_lat[[1]][j])
}
for (k in 1:length(constructos_excluidos)) {
constructos_excluidos[k] <- trimws(constructos_excluidos[k])
}
if (!is.null(constructos_excluidos)) {
for (l in 1:length(constructos_excluidos)) {
for (m in 1:length(var_lat[[1]])){
if (!(is.na(var_lat[[1]][m])) && constructos_excluidos[l] == var_lat[[1]][m]) {
var_lat[[1]][m] <- NA
}
}
}
}
HS.model_aux3[[1]][2] <- paste(var_lat[[1]][complete.cases(var_lat[[1]])], collapse=" + ")
HS.model_aux[i]<-paste((HS.model_aux3[[1]]), collapse="~")
}
HS.model_aux <- HS.model_aux[complete.cases(HS.model_aux)]
modelo2      <- NULL
HS.model2    <- NULL
for (i in 1:length(HS.model_aux)) {
var_lat_aux2 <- NULL
var_lat_aux2 <- (paste(unlist(HS.model_aux[i]),"\n"))
modelo2      <- paste(var_lat_aux2, collapse = " ")
HS.model2    <- paste(HS.model2, modelo2)
}
latent<-grep("=~", model, value=T)
reg<-grep("~", model, value = T)
reg<- reg[which(!reg %in%latent)]
constructos.regressoes <- NULL
for (i in 1:length(reg)) {
constructos.regressoes <- str_split(reg,"~" )
}
var_lat <- NULL
if (length(constructos.regressoes) > 0) {
for (i in 1:length(constructos.regressoes)) {
var_lat <- constructos.regressoes[[i]][2]
var_lat <- str_split(var_lat, c("\\+"))
for (j in 1:length(var_lat[[1]])) {
var_lat[[1]][j] <- trimws(var_lat[[1]][j])
}
for (j in 1:length(constructos_excluidos)) {
for (k in 1:length(var_lat[[1]])) {
if (constructos_excluidos[j] == var_lat[[1]][k]) {
var_lat[[1]][k] <- NA
}
}
var_lat[[1]] <- var_lat[[1]][complete.cases(var_lat[[1]])]
}
var_lat <- paste(unlist(var_lat[[1]]), collapse="+")
constructos.regressoes[[i]][2] <- var_lat
reg[i] <- paste(unlist(constructos.regressoes[[i]]), collapse = "~")
}
}
if (length(reg)>0) {
HS.model2    <- paste(HS.model2, " # \n")
HS.model2 <- paste(HS.model2,paste(unlist(reg), collapse = " \n "), sep="")
}
return(HS.model2)
}
############## VFFF ####
detect.outliers <- function (data_raw, variaveis_do_modelo) {
##### imputar medias para missing values ####
## transformar as vaiaveis usadas em numericas
indices_colunas <-  which(colnames(data_raw) %in% variaveis_do_modelo)
for(i in 1:length(indices_colunas)){
j <- indices_colunas[i]
data_raw[,j] <-  as.numeric(as.character(data_raw[,j]))
}
indices_colunas <- variaveis_do_modelo
# Finalmente, vamos adicionar a media nos NA's das variaveis
# imputar medias gerais pra cada variavel
data_raw$concatenar<-do.call(paste, as.list(data_raw[,quebras]))
# percorrer cada individuo, em cada variavel, ver se esta nulo e colocar
# a media da variavel conforme a vertical que pertence
for(k in 1:length(indices_colunas)){
j<-indices_colunas[k]
teste_nan <- NULL
teste_nan <- aggregate(data_raw[,j],
list(data_raw$concatenar),
mean,
na.rm=T)
svy.df <- NULL
svy.df <- svydesign(id=~ResponseId,
weights=~WEIGHT,
data=data_raw)
media_geal_aux <- NULL
media_geal_aux <- svymean(~data_raw[,j],
design=svy.df,
na.rm=T,
deff=T)[1]
teste_nan$x[is.nan(teste_nan$x)] <- media_geal_aux
for(i in 1:nrow(data_raw)){
vertical_aux<-data_raw$concatenar[i]
if(is.na(data_raw[i,j])){
#print(paste(i," ", j))
data_raw[i,j] <- teste_nan$x[teste_nan$Group.1==vertical_aux]
}
}
}
data_raw$D <- sqrt(
heplots::Mahalanobis(data_raw[,variaveis_do_modelo],
colMeans(data_raw[,variaveis_do_modelo]),
cov(data_raw[,variaveis_do_modelo]))
)
data_raw$outliers <- F
data_raw$outliers[data_raw$D > sqrt(qchisq(0.999, df = length(variaveis_do_modelo)))] <- T
#table(data_raw$outliers)
data_raw$var <- apply(data_raw[,variaveis_do_modelo], 1, var)
data_raw$outliers[data_raw$var < 0.1] <- T
#table(data_raw$outliers)
data_raw <- data_raw[which(data_raw$outliers == F),]
return(data_raw)
}
packages <- c('boot','foreign','doParallel','stringr','httpuv',
'lavaan','semTools','survey',
'tidyverse','rdrop2','RCurl','matrixcalc',
'reshape2','graphics','mvoutlier','psych','heplots')
inst.pack <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
if (Sys.getenv("JAVA_HOME")!="")
Sys.setenv(JAVA_HOME="")
library(rJava)
inst.pack(packages)
library(rJava)
if (Sys.getenv("JAVA_HOME")!="")
Sys.setenv(JAVA_HOME="")
library(rJava)
library(XLConnect)
install.packages("rJava")
install.packages("XLConnect")
library(rJava)
library(XLConnect)
source('C:/Users/ucaballero/Desktop/SurveyAnalysis.R')
source('C:/Users/ucaballero/Desktop/SurveyAnalysis.R')
View(do.sem)
library(rJava)
source('C:/Users/ucaballero/Desktop/SurveyAnalysis.R')
30000/20
30000/20/8
30000/20/8/24.8
11*4
11*4*5*3
30000/20/8/24.8+
x
30000*14
(30000*14)/12
35000/20/8/24.8
12*4*4*3
12*4*5*3
720*24.8
13*4*5*3
14*4*5*3
15*4*5*3
2928/3
clr
2928*24.8
16*15*14
choose(3,1)
choose(3,2)
choose(3,3)
2758/24.8
20*8
20*8*24.5
(20*8*24.5)/33
119-90
29*33
90/8
20*24.8
1+1
a <- 1
?mtcars
setwd("/")
setwd("Users/ucaballero/Desktop/repositories/Survey analysis/")
survey <- read.csv("survey.csv",header = T,sep = ",", encoding = "UTF-8")
column_names <- read.csv("column_names_tratados.csv",header = T,sep = ";")
!(names(survey) %in% c("Numero.de.cuenta"))
survey <- survey[,!(names(survey) %in% c("Numero.de.cuenta"))]
str(survey)
summary(survey)
survey
head(survey,2)
tail(survey,2)
column_names <- column_names[ !(column_names$translation == "") , !(names(column_names) %in% c("X")) ]
column_names$translation <- as.character(column_names$translation)
names(survey) <- column_names$translation
head(survey)
write.csv(survey,"survey_cleaned.csv",row.names = F)
survey <- read.csv("survey_cleaned.csv", sep = ",", header = T)
head(survey)
table(survey$jornada)
prop.table(table(survey$jornada),1)
prop.table(table(survey$jornada),0)
prop.table(table(survey$jornada),2)
prop.table(table(survey$jornada),1)
table(survey$jornada)
prop.table(table(survey$jornada))
as.data.frame(prop.table(table(survey$jornada)))
df <- as.data.frame(prop.table(table(survey$jornada)))
library(dplyr)
df <- as.data.frame(prop.table(table(survey$jornada)))
df %>% sort(Freq)
df$Freq
df %>% sort(Freq,1)
df %>% arrange(Freq,1)
df %>% arrange(Freq)
df %>% arrange(-Freq)
df %>% arrange(-Freq) %>% select(Freq)
freq <- df %>% arrange(-Freq) %>% select(Freq)
boxplot(freq)
quartile(freq)
quantile(freq)
quantile(freq$Freq)
hist(freq$Freq)
chisq.test(df$Freq)
table(survey$jornada)
chisq.test(survey$jornada)
table(survey$jornada)
as.data.frame(table(survey$jornada))
chisq.test(as.data.frame(table(survey$jornada))$Freq)
qqplot(as.data.frame(table(survey$jornada))$Freq)
qqplot(as.data.frame(table(survey$jornada))$Freq, y = NULL)
qqplot(as.data.frame(table(survey$jornada))$Freq, y = NULL,, distribution = "norm")
qqplot(as.data.frame(table(survey$jornada))$Freq, y = NULL,las=1, distribution = "norm")
qqPlot(as.data.frame(table(survey$jornada))$Freq, y = NULL,las=1, distribution = "norm")
qqnorm(as.data.frame(table(survey$jornada))$Freq)
require(MASS)
df_freq <- as.data.frame(table(survey$jornada))
df_perc <- as.data.frame(prop.table(table(survey$jornada)))
df_freq <- as.data.frame(table(survey$jornada))
qqnorm(df_freq$Freq)
ajuste <- fitdistr(df_freq$Freq)
ajuste <- fitdistr(df_freq$Freq,"normal")
ajuste
chisq.test(df_freq$Freq)
names(survey)
table(survey$jornada,survey$trabaja)
chisq.test(table(survey$jornada,survey$trabaja))
chisq.test(table(survey$trabaja,survey$jornada))
table(survey$trabaja,survey$jornada)
chisq.test(table(survey$bloques_libres,survey$trabaja))
table(survey$bloques_libres,survey$trabaja)
chisq.test(table(survey$bloques_libres,survey$edad))
chisq.test(table(survey$bloques_libres,survey$internet_permanente))
table(survey$bloques_libres,survey$internet_permanente)
qq(df_freq$Freq)
qqmath(df_freq$Freq)
qqline(df_freq$Freq)
qq(df_freq$Freq)
table(survey$jornada)
require(MASS)
library(dplyr)
setwd("/")
setwd("Users/ucaballero/Desktop/repositories/Survey analysis/")
survey <- read.csv("survey_cleaned.csv", sep = ",", header = T)
head(survey)
table(survey$jornada)
df_perc <- as.data.frame(prop.table(table(survey$jornada)))
df_freq <- as.data.frame(table(survey$jornada))
df_perc
df_freq %>% arrange(Freq)
df_freq %>% arrange(-Freq)
df_perc %>% arrange(-Freq)
hist(df_perc$Freq)
hist(df_perc$Freq,breaks = 5)
hist(df_perc$Freq,breaks = 10)
hist(df_perc$Freq,breaks = 4)
hist(df_perc$Freq,breaks = 3)
hist(df_perc$Freq,breaks = 5)
hist(df_perc$Freq,breaks = 6)
hist(df_freq$Freq,breaks = 6)
hist(df_freq$Freq,breaks = 4)
df_freq
df_freq %>% arrange(-Freq)
boxplot(df_freq$Freq)
hist(df_perc$Freq,breaks = 4)
df_perc %>% arrange(-Freq)
df_perc$categoria <- ""
df_perc
df_perc[df_perc$Var1 %in% c("Mañana, Noche","Mañana, Tarde, Noche"), "categoria" ] <- "Jornada Completa"
df_perc[df_perc$Var1 %in% c("Noche","Tarde"), "categoria" ] <- "Unica Jornada"
df_perc[df_perc$Var1 %in% c("Tarde, Noche"), "categoria" ] <- "Doble Jornada"
df_perc %>% arrange(-Freq)
df_perc <- df_perc[,!(names(df_perf) %in% c("Freq"))]
df_perc <- df_perc[,!(names(df_perc) %in% c("Freq"))]
df_perc
head(survey)
left_join(survey,df_perc,by=c("jornada"="categoria"))
left_join(survey,df_perc,by=c("jornada"="Var1"))
setwd("/")
setwd("Users/ucaballero/Desktop/repositories/Survey analysis/")
survey <- read.csv("survey_cleaned.csv", sep = ",", header = T)
summary(survey)
nrow(survey)
table(survey$jornada)
prop.table(table(survey$jornada))
as.data.frame(prop.table(table(survey$jornada)))
library(dplyr)
library(dplyr)
df_perc <- as.data.frame(prop.table(table(survey$jornada)))
df_perc
df_perc %>% arrange(Freq)
df_perc %>% arrange(-Freq)
df_perc <- df_perc %>% arrange(-Freq)
df_perc
boxplot(df_perc$Freq)
str(survey)
survey$jornada <- as.character(survey$jornada)
head(survey)
survey[4,]
survey[4,"Jornada"] <- "Mañana"
survey[4,"Jornada"]
df_perc <- as.data.frame(prop.table(table(survey$jornada)))
table(survey$jornada)
head(survey)
survey <- read.csv("survey_cleaned.csv", sep = ",", header = T)
survey$jornada <- as.character(survey$jornada)
survey[4,"jornada"] <- "Mañana"
table(survey$jornada)
prop.table(table(survey$jornada)
)
df_perc <- df_perc %>% arrange(-Freq)
df_freq
df_ferc
df_perc
df_perc <- as.data.frame(prop.table(table(survey$jornada)))
df_perc <- df_perc %>% arrange(-Freq)
df_perc
boxplot(df_perc$Freq)
data.frame(Var1=c("YY"),Freq=.99)
df_perc <- rbind(df_perf, data.frame(Var1=c("YY"),Freq=.99))
df_perc <- rbind(df_perc, data.frame(Var1=c("YY"),Freq=.99))
df_perc
df_perc <- df_perc %>% arrange(-Freq)
df_perc
boxplot(df_perc$Freq)
survey <- read.csv("survey_cleaned.csv", sep = ",", header = T)
df_perc <- as.data.frame(prop.table(table(survey$jornada)))
df_perc <- df_perc %>% arrange(-Freq)
df_perc
boxplot(df_perc$Freq)
boxplot(survey$uv)
hist(df_perc$Freq)
qqnorm(df_perc$Freq)
hist(df_perc$Freq)
df_perc[df_perc$Var1 %in% c("Mañana, Tarde, Noche","Mañana, Noche") , "categoria"] <- "Jornada Completa"
df_perc[df_perc$Var1 %in% c("Tarde","Noche") , "categoria"] <- "Unica Jornada"
df_perc[df_perc$Var1 %in% c("Tarde, Noche") , "categoria"] <- "Doble Jornada"
df_perc
df_perc <- df_perc %>% select(Var1,categoria)
df_perc
df_perc %>% select(Var1,categoria)
df_perc <- df_perc %>% select("Var1","categoria")
df_perc
df_perc %>% select(Var1,categoria)
library(dplyr)
df_perc %>% select(Var1,categoria)
#install.packages("dplyr")
library(plyr)
library(dplyr)
df_perc <- df_perc %>% select(Var1,categoria)
df_perc
df_perc %>% head
remove.packages("MASS", lib="C:/Program Files/Microsoft/R Client/R_SERVER/library")
df_perc %>% select(Var1)
